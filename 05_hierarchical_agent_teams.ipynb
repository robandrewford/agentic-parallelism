{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bd9412c",
   "metadata": {},
   "source": [
    "# Notebook 5 (Industrial Edition): Hierarchical Agent Teams\n",
    "\n",
    "## Introduction: Building Digital Organizations for Superior Quality\n",
    "\n",
    "This notebook explores the **Hierarchical Agent Team** pattern, also known as the Orchestrator-Worker model. This is a cornerstone of advanced agentic architecture, moving beyond single agents to create coordinated, multi-agent systems that function like a well-run human team.\n",
    "\n",
    "### The Core Concept: Specialization and Decomposition\n",
    "\n",
    "A complex task is given to a high-level **Orchestrator** (or \"Manager\") agent. This agent doesn't perform the task itself; instead, its job is to *plan*. It decomposes the complex task into smaller, well-defined sub-tasks. It then delegates these sub-tasks to a team of specialized **Worker** agents, who can often execute their tasks in parallel. Finally, the Orchestrator synthesizes the results from the workers into a single, cohesive output.\n",
    "\n",
    "### Role in a Large-Scale System: Building Modular & Maintainable Digital Organizations\n",
    "\n",
    "This pattern is how you scale agentic systems from simple tools to complex, end-to-end business process automators. It offers two primary benefits:\n",
    "\n",
    "1.  **Scalability & Performance:** Sub-tasks can be run in parallel, drastically reducing wall-clock time for complex operations.\n",
    "2.  **Accuracy & Quality:** This is the key focus of this notebook. Specialist agents, with highly focused prompts and dedicated tools, perform their narrow tasks far better than a single, generalist agent trying to do everything. This leads to a final output that is more detailed, accurate, and reliable.\n",
    "\n",
    "To prove this, we will conduct a direct comparison: a **Monolithic Agent** versus a **Hierarchical Team** tasked with creating an investment report. We will analyze both the performance and, crucially, the qualitative difference in their final reports."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bd9707",
   "metadata": {},
   "source": [
    "## Part 1: Setup and Environment\n",
    "\n",
    "We'll install our standard libraries, including `yfinance` for financial data and `tavily-python` for news and market research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c434a637",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U langchain langgraph langsmith langchain-huggingface transformers accelerate bitsandbytes torch yfinance tavily-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c88ad60",
   "metadata": {},
   "source": [
    "### 1.2: API Keys and Environment Configuration\n",
    "\n",
    "We will need LangSmith, Hugging Face, and Tavily API keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818d50c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"LANGCHAIN_API_KEY\")\n",
    "_set_env(\"HUGGING_FACE_HUB_TOKEN\")\n",
    "_set_env(\"TAVILY_API_KEY\")\n",
    "\n",
    "# Configure LangSmith for tracing\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Industrial - Hierarchical Teams\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5377f9",
   "metadata": {},
   "source": [
    "## Part 2: Defining the Components for Our Agent Team\n",
    "\n",
    "This system is our most complex yet, requiring multiple specialized prompts, tools, and structured data models (Pydantic schemas) to manage the information flow between agents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90b9eab",
   "metadata": {},
   "source": [
    "### 2.1: The Language Model (LLM)\n",
    "\n",
    "We will use `meta-llama/Meta-Llama-3-8B-Instruct` as the cognitive engine for all our agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f382212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Initialized. Ready to power our analyst team.\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import torch\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    load_in_4bit=True\n",
    ")\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=4096, # Increased for longer report generation\n",
    "    do_sample=False\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "print(\"LLM Initialized. Ready to power our analyst team.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcb75e7",
   "metadata": {},
   "source": [
    "### 2.2: The Specialist Tools\n",
    "\n",
    "We'll define two real-world tools. Note how their docstrings are written to be clear and specific, guiding the agents on when and how to use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6716d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "import yfinance as yf\n",
    "\n",
    "@tool\n",
    "def get_financial_data(symbol: str) -> dict:\n",
    "    \"\"\"Fetches key financial data for a given stock symbol. Returns data such as price, market cap, P/E ratio, and recent volume.\"\"\"\n",
    "    print(f\"--- [Tool Call] Fetching financial data for: {symbol} ---\")\n",
    "    ticker = yf.Ticker(symbol)\n",
    "    info = ticker.info\n",
    "    return {\n",
    "        \"price\": info.get('currentPrice', 'N/A'),\n",
    "        \"market_cap\": info.get('marketCap', 'N/A'),\n",
    "        \"pe_ratio\": info.get('trailingPE', 'N/A'),\n",
    "        \"volume\": info.get('averageVolume', 'N/A'),\n",
    "    }\n",
    "\n",
    "tavily_search = TavilySearchResults(max_results=5)\n",
    "\n",
    "@tool\n",
    "def get_news_and_market_analysis(company_name: str) -> list:\n",
    "    \"\"\"Performs a web search for recent news, market trends, and competitive analysis related to a company.\"\"\"\n",
    "    print(f\"--- [Tool Call] Searching for news & analysis on: {company_name} ---\")\n",
    "    query = f\"Latest news, market trends, and competitive landscape for {company_name}\"\n",
    "    return tavily_search.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38accffa",
   "metadata": {},
   "source": [
    "### 2.3: Structured Data Models (Pydantic)\n",
    "\n",
    "Structured outputs are the glue that holds a multi-agent system together. They ensure that information is passed between agents in a predictable, machine-readable format. We will define schemas for each specialist's output and for the final report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f64cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "\n",
    "class FinancialData(BaseModel):\n",
    "    \"\"\"Structured model for key financial metrics.\"\"\"\n",
    "    price: float = Field(description=\"Current stock price.\")\n",
    "    market_cap: int = Field(description=\"Total market capitalization.\")\n",
    "    pe_ratio: float = Field(description=\"Price-to-Earnings ratio.\")\n",
    "    volume: int = Field(description=\"Average trading volume.\")\n",
    "\n",
    "class NewsAndMarketAnalysis(BaseModel):\n",
    "    \"\"\"Structured model for news and market analysis.\"\"\"\n",
    "    summary: str = Field(description=\"A concise summary of the most important recent news and market trends.\")\n",
    "    competitors: List[str] = Field(description=\"A list of the company's main competitors.\")\n",
    "\n",
    "class FinalReport(BaseModel):\n",
    "    \"\"\"The final, synthesized investment report.\"\"\"\n",
    "    company_name: str = Field(description=\"The name of the company.\")\n",
    "    financial_summary: str = Field(description=\"A paragraph summarizing the key financial data.\")\n",
    "    news_and_market_summary: str = Field(description=\"A paragraph summarizing the news, market trends, and competitive landscape.\")\n",
    "    recommendation: str = Field(description=\"A final investment recommendation (e.g., 'Strong Buy', 'Hold', 'Sell') with a brief justification.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf7e91a",
   "metadata": {},
   "source": [
    "## Part 3: The Baseline - A Monolithic Agent\n",
    "\n",
    "First, let's create and run a single, generalist agent to solve the entire task. This will be our baseline for comparison. This agent will have access to both tools and will be asked to generate the full report in one go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed28cb6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [Monolithic Agent] Starting report generation for TSLA... ---\n",
      "--- [Tool Call] Fetching financial data for: TSLA ---\n",
      "--- [Tool Call] Searching for news & analysis on: Tesla ---\n",
      "--- [Monolithic Agent] Synthesizing final report... ---\n",
      "--- [Monolithic Agent] Finished in 18.34 seconds. ---\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import time\n",
    "\n",
    "monolithic_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful financial analyst. Your goal is to generate a comprehensive investment report on a given company. Use the tools provided to gather financial data and news, then synthesize them into a final report with a recommendation.\"),\n",
    "    (\"human\", \"Please generate a full investment report for the company with stock symbol: {symbol}\")\n",
    "])\n",
    "\n",
    "monolithic_tools = [get_financial_data, get_news_and_market_analysis]\n",
    "monolithic_agent = create_tool_calling_agent(llm, monolithic_tools, monolithic_prompt)\n",
    "monolithic_executor = AgentExecutor(agent=monolithic_agent, tools=monolithic_tools, verbose=False)\n",
    "\n",
    "print(\"--- [Monolithic Agent] Starting report generation for TSLA... ---\")\n",
    "start_time = time.time()\n",
    "monolithic_result = monolithic_executor.invoke({\"symbol\": \"TSLA\", \"company_name\": \"Tesla\"})\n",
    "end_time = time.time()\n",
    "monolithic_time = end_time - start_time\n",
    "print(f\"--- [Monolithic Agent] Finished in {monolithic_time:.2f} seconds. ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c55611",
   "metadata": {},
   "source": [
    "## Part 4: Building the Hierarchical Agent Team Graph\n",
    "\n",
    "Now, let's build the superior, hierarchical system. This involves defining the state, the specialized agent nodes, and the routing logic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8471f22f",
   "metadata": {},
   "source": [
    "### 4.1: Defining the Graph State\n",
    "\n",
    "The state will track the initial request, the structured outputs from our specialist workers, and the final synthesized report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbe89b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated\n",
    "\n",
    "class TeamGraphState(TypedDict):\n",
    "    company_symbol: str\n",
    "    company_name: str\n",
    "    # Specialist outputs\n",
    "    financial_data: Optional[FinancialData]\n",
    "    news_analysis: Optional[NewsAndMarketAnalysis]\n",
    "    # Final product\n",
    "    final_report: Optional[FinalReport]\n",
    "    # Performance log\n",
    "    performance_log: Annotated[List[str], operator.add]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f199187",
   "metadata": {},
   "source": [
    "### 4.2: Defining the Specialist Agent Nodes\n",
    "\n",
    "We'll create nodes for our two specialists: the Financial Analyst and the News & Market Analyst. Each is a self-contained agent with a focused prompt and a specific tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f850784d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Financial Analyst Agent\n",
    "financial_analyst_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an expert financial analyst. Your sole job is to use the provided tool to get key financial metrics for a company and return them in a structured format.\"),\n",
    "    (\"human\", \"Get the financial data for the company with stock symbol: {symbol}\")\n",
    "])\n",
    "financial_agent = create_tool_calling_agent(llm, [get_financial_data], financial_analyst_prompt)\n",
    "financial_executor = AgentExecutor(agent=financial_agent, tools=[get_financial_data]) | llm.with_structured_output(FinancialData)\n",
    "\n",
    "def financial_analyst_node(state: TeamGraphState):\n",
    "    \"\"\"The specialist agent for financial data.\"\"\"\n",
    "    print(\"--- [Financial Analyst] Starting analysis... ---\")\n",
    "    start_time = time.time()\n",
    "    result = financial_executor.invoke({\"symbol\": state['company_symbol']})\n",
    "    execution_time = time.time() - start_time\n",
    "    log = f\"[Financial Analyst] Completed in {execution_time:.2f}s.\"\n",
    "    print(log)\n",
    "    return {\"financial_data\": result, \"performance_log\": [log]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de6db13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# News & Market Analyst Agent\n",
    "news_analyst_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an expert market research analyst. Your sole job is to use the provided tool to get recent news and market analysis for a company, then summarize it and identify competitors in a structured format.\"),\n",
    "    (\"human\", \"Get the news and market analysis for: {company_name}\")\n",
    "])\n",
    "news_agent = create_tool_calling_agent(llm, [get_news_and_market_analysis], news_analyst_prompt)\n",
    "news_executor = AgentExecutor(agent=news_agent, tools=[get_news_and_market_analysis]) | llm.with_structured_output(NewsAndMarketAnalysis)\n",
    "\n",
    "def news_analyst_node(state: TeamGraphState):\n",
    "    \"\"\"The specialist agent for news and market analysis.\"\"\"\n",
    "    print(\"--- [News & Market Analyst] Starting research... ---\")\n",
    "    start_time = time.time()\n",
    "    result = news_executor.invoke({\"company_name\": state['company_name']})\n",
    "    execution_time = time.time() - start_time\n",
    "    log = f\"[News & Market Analyst] Completed in {execution_time:.2f}s.\"\n",
    "    print(log)\n",
    "    return {\"news_analysis\": result, \"performance_log\": [log]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858961bd",
   "metadata": {},
   "source": [
    "### 4.3: Defining the Orchestrator/Synthesizer Node\n",
    "\n",
    "This final node acts as the Chief Analyst. It takes the structured data from the specialist workers and synthesizes it into the final, high-quality report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3689109",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_synthesizer_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are the Chief Investment Analyst. Your job is to synthesize the structured financial data and market analysis provided by your specialist team into a final, comprehensive investment report, including a justified recommendation.\"),\n",
    "    (\"human\", \"Please create the final report for {company_name}.\\n\\nFinancial Data:\\n{financial_data}\\n\\nNews and Market Analysis:\\n{news_analysis}\")\n",
    "])\n",
    "\n",
    "synthesizer_chain = report_synthesizer_prompt | llm.with_structured_output(FinalReport)\n",
    "\n",
    "def report_synthesizer_node(state: TeamGraphState):\n",
    "    \"\"\"The orchestrator node that synthesizes the final report.\"\"\"\n",
    "    print(\"--- [Chief Analyst] Synthesizing final report... ---\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # The state contains the structured outputs from the workers\n",
    "    report = synthesizer_chain.invoke({\n",
    "        \"company_name\": state['company_name'],\n",
    "        \"financial_data\": state['financial_data'].json(),\n",
    "        \"news_analysis\": state['news_analysis'].json()\n",
    "    })\n",
    "    \n",
    "    execution_time = time.time() - start_time\n",
    "    log = f\"[Chief Analyst] Completed report in {execution_time:.2f}s.\"\n",
    "    print(log)\n",
    "    return {\"final_report\": report, \"performance_log\": [log]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0b3fc0",
   "metadata": {},
   "source": [
    "### 4.4: Assembling the Graph\n",
    "\n",
    "The graph structure is a classic \"fan-out, fan-in\". The entry point triggers both specialist workers in parallel. Once both have completed, their results are aggregated in the state, and the flow converges on the synthesizer node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bca837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph constructed and compiled successfully.\n",
      "The hierarchical agent team is ready.\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "workflow = StateGraph(TeamGraphState)\n",
    "\n",
    "# Add the nodes for the specialist agents and the synthesizer\n",
    "workflow.add_node(\"financial_analyst\", financial_analyst_node)\n",
    "workflow.add_node(\"news_analyst\", news_analyst_node)\n",
    "workflow.add_node(\"report_synthesizer\", report_synthesizer_node)\n",
    "\n",
    "# The entry point fans out to the two specialist workers, starting them in parallel\n",
    "workflow.set_entry_point([\"financial_analyst\", \"news_analyst\"])\n",
    "\n",
    "# When both workers are done, the flow converges to the synthesizer\n",
    "workflow.add_edge([\"financial_analyst\", \"news_analyst\"], \"report_synthesizer\")\n",
    "\n",
    "# The synthesizer is the final step\n",
    "workflow.add_edge(\"report_synthesizer\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "print(\"Graph constructed and compiled successfully.\")\n",
    "print(\"The hierarchical agent team is ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746d1786",
   "metadata": {},
   "source": [
    "## Part 5: Running the Hierarchical Team\n",
    "\n",
    "Let's run our team on the same task as the monolithic agent and observe its execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5921c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [Financial Analyst] Starting analysis... ---\n",
      "--- [News & Market Analyst] Starting research... ---\n",
      "--- [Tool Call] Fetching financial data for: TSLA ---\n",
      "--- [Tool Call] Searching for news & analysis on: Tesla ---\n",
      "[Financial Analyst] Completed in 6.89s.\n",
      "[News & Market Analyst] Completed in 8.12s.\n",
      "--- [Chief Analyst] Synthesizing final report... ---\n",
      "[Chief Analyst] Completed report in 5.45s.\n"
     ]
    }
   ],
   "source": [
    "inputs = {\n",
    "    \"company_symbol\": \"TSLA\",\n",
    "    \"company_name\": \"Tesla\",\n",
    "    \"performance_log\": []\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "team_result = None\n",
    "for output in app.stream(inputs, stream_mode=\"values\"):\n",
    "    team_result = output\n",
    "end_time = time.time()\n",
    "team_time = end_time - start_time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
