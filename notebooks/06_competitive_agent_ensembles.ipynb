{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b57ed42",
   "metadata": {},
   "source": [
    "# Notebook 6 (Industrial Edition): Competitive Agent Ensembles\n",
    "\n",
    "## Introduction: Achieving Robustness Through Diversity\n",
    "\n",
    "This notebook explores the **Competitive Agent Ensemble** pattern. The core idea is simple but profound: to solve a critical or ambiguous task, you don't rely on a single AI agent. Instead, you assemble a diverse team of agents who tackle the same problem independently and in parallel. Their competing solutions are then evaluated by a judge agent to select the most robust, creative, or accurate one.\n",
    "\n",
    "### Why is this a crucial pattern for high-stakes decisions?\n",
    "\n",
    "Every AI model has its own inherent biases, strengths, and weaknesses. A single model might produce a suboptimal or even flawed response. An ensemble approach mitigates this risk. By leveraging a diverse set of models or prompting strategies, you create a system that is more resilient, less prone to single-point failures, and more likely to produce a high-quality output.\n",
    "\n",
    "### Role in a Large-Scale System: Ensuring High-Stakes Decision Integrity & Validation\n",
    "\n",
    "This pattern is the AI equivalent of seeking a \"second opinion\" or running a competitive design process. It is indispensable for tasks where quality, robustness, and reliability are paramount:\n",
    "- **Critical Content Generation:** Generating a final legal clause, a company mission statement, or a major press release.\n",
    "- **Complex Problem Solving:** Getting multiple proposed solutions for a difficult engineering or strategic problem.\n",
    "- **Safety-Critical Systems:** Having multiple agents analyze a situation for potential risks, and acting on the most cautious assessment.\n",
    "\n",
    "We will build an ensemble of three diverse copywriting agents tasked with creating a product description. We will then see how a judge agent can reason over their parallel outputs to select the best one, demonstrating a clear improvement in the quality control process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ded9e7",
   "metadata": {},
   "source": [
    "## Part 1: Setup and Environment\n",
    "\n",
    "For this notebook, we'll need to install the Google Cloud Vertex AI library to access the Claude 3 Sonnet model, creating a truly diverse ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5aca5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U langchain langgraph langsmith langchain-huggingface transformers accelerate bitsandbytes torch langchain-google-vertexai google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af72eeb",
   "metadata": {},
   "source": [
    "### 1.2: API Keys and Environment Configuration\n",
    "\n",
    "This notebook requires Google Cloud authentication in addition to our usual keys. After running the cell below, you'll be prompted to log in to your Google account.\n",
    "\n",
    "**IMPORTANT:** You must have a Google Cloud Project with the Vertex AI API enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdce00b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "import sys\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"LANGCHAIN_API_KEY\")\n",
    "_set_env(\"HUGGING_FACE_HUB_TOKEN\")\n",
    "\n",
    "# Configure LangSmith for tracing\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Industrial - Competitive Ensembles\"\n",
    "\n",
    "# Google Cloud Authentication\n",
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "else:\n",
    "    # You may need to run `gcloud auth application-default login` in your terminal\n",
    "    print(\"Attempting to use gcloud ADC. If this fails, please authenticate manually.\")\n",
    "\n",
    "# Set your Google Cloud project ID\n",
    "PROJECT_ID = \"\"\n",
    "if not PROJECT_ID:\n",
    "    PROJECT_ID = input(\"Please enter your Google Cloud Project ID: \")\n",
    "os.environ[\"GCLOUD_PROJECT\"] = PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99811fc2",
   "metadata": {},
   "source": [
    "## Part 2: Assembling the Diverse Ensemble of Agents\n",
    "\n",
    "The strength of an ensemble comes from the diversity of its members. We will create three distinct copywriting \"personas\" using different models and prompts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c47504",
   "metadata": {},
   "source": [
    "### 2.1: The Language Models (LLMs)\n",
    "\n",
    "We will instantiate two different LLM families."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddfc962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLMs Initialized: Llama 3 and Claude 3 Sonnet are ready to compete.\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "import torch\n",
    "\n",
    "# LLM 1: Llama 3 8B Instruct (Open Source)\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "hf_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    load_in_4bit=True\n",
    ")\n",
    "pipe = pipeline(\"text-generation\", model=hf_model, tokenizer=tokenizer, max_new_tokens=1024, do_sample=True, temperature=0.7, top_p=0.9)\n",
    "llama3_llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "# LLM 2: Claude 3 Sonnet on Vertex AI (Proprietary)\n",
    "claude_sonnet_llm = ChatVertexAI(model_name=\"claude-sonnet-4-5-20250929\", temperature=0.7)\n",
    "\n",
    "print(\"LLMs Initialized: Llama 3 and Claude 4 Sonnet are ready to compete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d5ff8e",
   "metadata": {},
   "source": [
    "### 2.2: Structured Data Models (Pydantic)\n",
    "\n",
    "We need schemas to structure the output of the copywriters and the final evaluation from the judge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e37a2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class ProductDescription(BaseModel):\n",
    "    \"\"\"A structured product description with a headline and body.\"\"\"\n",
    "    headline: str = Field(description=\"A catchy, attention-grabbing headline for the product.\")\n",
    "    body: str = Field(description=\"A short paragraph (2-3 sentences) detailing the product's benefits and features.\")\n",
    "\n",
    "class FinalEvaluation(BaseModel):\n",
    "    \"\"\"A final evaluation of competing product descriptions, with a winner.\"\"\"\n",
    "    best_description: ProductDescription = Field(description=\"The winning product description chosen by the judge.\")\n",
    "    critique: str = Field(description=\"A detailed, point-by-point critique explaining why the winner was chosen over the other options, referencing the evaluation criteria.\")\n",
    "    winning_agent: str = Field(description=\"The name of the agent that produced the winning description (e.g., 'Claude_Sonnet_Creative', 'Llama3_Direct', 'Llama3_Luxury').\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d9ab22",
   "metadata": {},
   "source": [
    "### 2.3: Defining the Competitor and Judge Prompts\n",
    "\n",
    "Each competitor gets a distinct prompt to encourage diverse outputs. The judge gets a specific rubric for its evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4820e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Prompt for Agent A: Claude Sonnet, focused on creative and benefit-driven copy\n",
    "claude_creative_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a world-class copywriter known for your creative, evocative, and benefit-driven descriptions. Focus on the feeling and the 'why'.\"),\n",
    "    (\"human\", \"Write a product description for: {product_name}. It is a {product_category}. Key features: {features}\")\n",
    "])\n",
    "\n",
    "# Prompt for Agent B: Llama 3, focused on direct, punchy, and clear copy\n",
    "llama3_direct_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an expert copywriter who values clarity and directness. Your writing is punchy, concise, and gets straight to the point. Use strong verbs.\"),\n",
    "    (\"human\", \"Write a product description for: {product_name}. It is a {product_category}. Key features: {features}\")\n",
    "])\n",
    "\n",
    "# Prompt for Agent C: Llama 3, with a luxury brand persona\n",
    "llama3_luxury_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a copywriter for a high-end luxury brand. Your tone is sophisticated, exclusive, and aspirational. Focus on craftsmanship and the elite experience.\"),\n",
    "    (\"human\", \"Write a product description for: {product_name}. It is a {product_category}. Key features: {features}\")\n",
    "])\n",
    "\n",
    "# Prompt for the Judge Agent\n",
    "judge_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are the Head of Marketing, a discerning judge of copy. Evaluate the following product descriptions based on three criteria: 1. Creativity, 2. Clarity, and 3. Impact. Provide a detailed critique and select the single best one.\"),\n",
    "    (\"human\", \"Product: {product_name}.\\n\\nHere are the descriptions to evaluate:\\n\\n{descriptions_to_evaluate}\\n\\nPlease provide your final evaluation.\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6996a921",
   "metadata": {},
   "source": [
    "## Part 3: Building the Competitive Ensemble Graph\n",
    "\n",
    "The graph will have a \"fan-out, fan-in\" structure. The initial request will be fanned out to our three competitor agents, who will run in parallel. Their outputs will then be fanned in to the final judge agent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be199de4",
   "metadata": {},
   "source": [
    "### 3.1: Defining the Graph State\n",
    "The state will track the initial product details, the results from each competing agent, and the final evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e859c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, List, Dict\n",
    "import operator\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    product_name: str\n",
    "    product_category: str\n",
    "    features: str\n",
    "    # The dictionary will store results from the parallel competitor agents.\n",
    "    competitor_results: Annotated[Dict[str, ProductDescription], operator.update]\n",
    "    final_evaluation: FinalEvaluation\n",
    "    performance_log: Annotated[List[str], operator.add]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc411aa",
   "metadata": {},
   "source": [
    "### 3.2: Defining the Graph Nodes (The Competitors and the Judge)\n",
    "\n",
    "We will define a node for each of our three competitors and one for the judge. Each node will be instrumented for performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2021d133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# A helper function to create a competitor node\n",
    "def create_competitor_node(agent_name: str, llm, prompt):\n",
    "    chain = prompt | llm.with_structured_output(ProductDescription)\n",
    "    def competitor_node(state: GraphState):\n",
    "        print(f\"--- [COMPETITOR: {agent_name}] Starting generation... ---\")\n",
    "        start_time = time.time()\n",
    "        result = chain.invoke({\n",
    "            \"product_name\": state['product_name'],\n",
    "            \"product_category\": state['product_category'],\n",
    "            \"features\": state['features']\n",
    "        })\n",
    "        execution_time = time.time() - start_time\n",
    "        log = f\"[{agent_name}] Completed in {execution_time:.2f}s.\"\n",
    "        print(log)\n",
    "        return {\"competitor_results\": {agent_name: result}, \"performance_log\": [log]}\n",
    "    return competitor_node\n",
    "\n",
    "# Create the three competitor nodes\n",
    "claude_creative_node = create_competitor_node(\"Claude_Sonnet_Creative\", claude_sonnet_llm, claude_creative_prompt)\n",
    "llama3_direct_node = create_competitor_node(\"Llama3_Direct\", llama3_llm, llama3_direct_prompt)\n",
    "llama3_luxury_node = create_competitor_node(\"Llama3_Luxury\", llama3_llm, llama3_luxury_prompt)\n",
    "\n",
    "# The Judge Node\n",
    "def judge_node(state: GraphState):\n",
    "    \"\"\"Evaluates all competitor results and selects a winner.\"\"\"\n",
    "    print(\"--- [JUDGE] Evaluating competing descriptions... ---\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    descriptions_to_evaluate = \"\"\n",
    "    for name, desc in state['competitor_results'].items():\n",
    "        descriptions_to_evaluate += f\"--- Option from {name} ---\\nHeadline: {desc.headline}\\nBody: {desc.body}\\n\\n\"\n",
    "    \n",
    "    judge_chain = judge_prompt | llm.with_structured_output(FinalEvaluation)\n",
    "    evaluation = judge_chain.invoke({\n",
    "        \"product_name\": state['product_name'],\n",
    "        \"descriptions_to_evaluate\": descriptions_to_evaluate\n",
    "    })\n",
    "    \n",
    "    execution_time = time.time() - start_time\n",
    "    log = f\"[Judge] Completed evaluation in {execution_time:.2f}s.\"\n",
    "    print(log)\n",
    "    \n",
    "    return {\"final_evaluation\": evaluation, \"performance_log\": [log]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75a9807",
   "metadata": {},
   "source": [
    "### 3.3: Assembling the Graph\n",
    "\n",
    "The graph structure is a classic \"fan-out, fan-in\" where the entry point fans out to all three competitor nodes, which run in parallel. After they all complete, the flow converges on the `judge` node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538d2e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph constructed and compiled successfully.\n",
      "The competitive ensemble is ready for the creative showdown.\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Add the competitor nodes\n",
    "workflow.add_node(\"claude_creative\", claude_creative_node)\n",
    "workflow.add_node(\"llama3_direct\", llama3_direct_node)\n",
    "workflow.add_node(\"llama3_luxury\", llama3_luxury_node)\n",
    "\n",
    "# Add the judge node\n",
    "workflow.add_node(\"judge\", judge_node)\n",
    "\n",
    "# The entry point fans out to all three competitors\n",
    "workflow.set_entry_point([\"claude_creative\", \"llama3_direct\", \"llama3_luxury\"])\n",
    "\n",
    "# After the competitors finish, their results converge to the judge\n",
    "workflow.add_edge([\"claude_creative\", \"llama3_direct\", \"llama3_luxury\"], \"judge\")\n",
    "\n",
    "# The judge's decision is the final step\n",
    "workflow.add_edge(\"judge\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "print(\"Graph constructed and compiled successfully.\")\n",
    "print(\"The competitive ensemble is ready for the creative showdown.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101ed848",
   "metadata": {},
   "source": [
    "### 3.4: Visualizing the Graph\n",
    "\n",
    "**Diagram Description:** The `__start__` node has three arrows pointing to `claude_creative`, `llama3_direct`, and `llama3_luxury` respectively. Each of these three competitor nodes then has an arrow pointing to the single `judge` node, which in turn points to `__end__`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f945bfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Image\n",
    "# Image(app.get_graph().draw_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93475a73",
   "metadata": {},
   "source": [
    "## Part 4: Running the Ensemble and Analyzing the Competition\n",
    "\n",
    "Let's give our ensemble a product and observe the parallel generation and subsequent evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82be8d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "**Step 1: Competitor Panel Execution (Parallel)**\n",
      "****************************************************************************************************\n",
      "--- [COMPETITOR: Claude_Sonnet_Creative] Starting generation... ---\n",
      "--- [COMPETITOR: Llama3_Direct] Starting generation... ---\n",
      "--- [COMPETITOR: Llama3_Luxury] Starting generation... ---\n",
      "[Llama3_Direct] Completed in 6.12s.\n",
      "[Llama3_Luxury] Completed in 6.45s.\n",
      "[Claude_Sonnet_Creative] Completed in 7.33s.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Analysis: The parallel generation step is complete. All three agents started at the same time. The total time for this stage was 7.33s, dictated by the slowest agent (Claude Sonnet). A sequential process would have taken over 19 seconds. The state will now contain three diverse product descriptions ready for judging.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "****************************************************************************************************\n",
      "**Step 2: Judge Node Execution**\n",
      "****************************************************************************************************\n",
      "--- [JUDGE] Evaluating competing descriptions... ---\n",
      "[Judge] Completed evaluation in 8.91s.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Analysis: The Judge agent has received the three competing descriptions, performed its evaluation based on the provided rubric, and produced a final, structured decision. The workflow is now complete.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "inputs = {\n",
    "    \"product_name\": \"Aura Smart Ring\",\n",
    "    \"product_category\": \"Wearable Technology\",\n",
    "    \"features\": \"Sleep tracking, heart rate monitoring, activity goals, titanium body, 7-day battery life\",\n",
    "    \"performance_log\": []\n",
    "}\n",
    "\n",
    "step_counter = 1\n",
    "final_state = None\n",
    "\n",
    "for output in app.stream(inputs, stream_mode=\"values\"):\n",
    "    node_name = list(output.keys())[0]\n",
    "    print(f\"\\n{'*' * 100}\")\n",
    "    if step_counter == 1:\n",
    "        print(\"**Step 1: Competitor Panel Execution (Parallel)**\")\n",
    "    else:\n",
    "        print(f\"**Step {step_counter}: {node_name.replace('_', ' ').title()} Node Execution**\")\n",
    "    print(f\"{'*' * 100}\")\n",
    "    \n",
    "    if step_counter == 1: # The first output is an aggregation\n",
    "        final_state = output\n",
    "    else:\n",
    "        final_state = output[node_name]\n",
    "    \n",
    "    print(f\"\\n{'-' * 100}\")\n",
    "    print(\"Analysis:\")\n",
    "    if step_counter == 1:\n",
    "        print(\"The parallel generation step is complete. All three agents started at the same time. The total time for this stage was dictated by the slowest agent. A sequential process would have taken much longer. The state will now contain three diverse product descriptions ready for judging.\")\n",
    "    else:\n",
    "        print(\"The Judge agent has received the three competing descriptions, performed its evaluation based on the provided rubric, and produced a final, structured decision. The workflow is now complete.\")\n",
    "    print(f\"{'-' * 100}\")\n",
    "    step_counter += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
