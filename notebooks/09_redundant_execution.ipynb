{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2a48887",
   "metadata": {},
   "source": [
    "# Notebook 9 (Industrial Edition): Redundant Execution for Fault Tolerance\n",
    "\n",
    "## Introduction: Building Resilient and Predictable AI Systems\n",
    "\n",
    "This notebook explores **Redundant Execution**, a critical pattern for building highly reliable and performant AI systems. The concept is straightforward: for a critical and potentially unreliable step, execute two or more identical agents in parallel. The system then uses the result from the first agent to successfully finish and cancels the rest. This is a powerful technique for mitigating the risks of unreliable dependencies, like external APIs or even the stochastic nature of LLMs themselves.\n",
    "\n",
    "### Why is this essential for production systems?\n",
    "\n",
    "Production systems cannot afford to fail. However, agents often rely on external services (APIs, databases) that can be slow or fail intermittently. A single failure can cascade and bring down an entire workflow. Redundant execution provides a powerful defense:\n",
    "\n",
    "1.  **Fault Tolerance:** If one agent fails (e.g., due to a network error), the other can still succeed, ensuring the overall process continues. This drastically increases the system's uptime and success rate.\n",
    "2.  **Latency Consistency:** Network calls often suffer from \"long-tail latency,\" where most calls are fast but a small percentage are extremely slow. Redundant execution protects against this by ensuring the process completes as fast as the *fastest* parallel call, not the slowest.\n",
    "\n",
    "### Role in a Large-Scale System: Guaranteeing Mission-Critical System Reliability & Uptime\n",
    "\n",
    "This is a core infrastructure pattern for building robust, mission-critical systems:\n",
    "- **Financial Trading:** Ensuring an order is executed even if one API endpoint is down.\n",
    "- **Real-time Bidding:** Getting an ad bid back within a strict time limit, even if one model server is slow.\n",
    "- **Critical Customer Support:** Guaranteeing that a crucial data lookup for a frustrated customer succeeds quickly.\n",
    "\n",
    "We will build a simple agent that relies on an unreliable, simulated tool. We will then run it with and without redundant execution to demonstrate the dramatic improvements in both speed and success rate (i.e., effective accuracy)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf9b807",
   "metadata": {},
   "source": [
    "## Part 1: Setup and Environment\n",
    "\n",
    "We'll install our standard libraries. No external tool APIs are needed as we will simulate unreliability to have full control over the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94ed07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U langchain langgraph langsmith langchain-huggingface transformers accelerate bitsandbytes torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35a4fcc",
   "metadata": {},
   "source": [
    "### 1.2: API Keys and Environment Configuration\n",
    "\n",
    "We will need our LangSmith and Hugging Face keys for tracing and model access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539b3df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"LANGCHAIN_API_KEY\")\n",
    "_set_env(\"HUGGING_FACE_HUB_TOKEN\")\n",
    "\n",
    "# Configure LangSmith for tracing\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Industrial - Redundant Execution\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c78c28",
   "metadata": {},
   "source": [
    "## Part 2: Components for the Resilient Agent\n",
    "\n",
    "We need to define our LLM and a special tool that is *intentionally* unreliable to simulate real-world conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69df126a",
   "metadata": {},
   "source": [
    "### 2.1: The Language Model (LLM)\n",
    "\n",
    "We will use `meta-llama/Meta-Llama-3-8B-Instruct` as the brain for our identical agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec5e87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Initialized. Ready to power our resilient agents.\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import torch\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.bfloat16, device_map=\"auto\", load_in_4bit=True)\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=512, do_sample=False)\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "print(\"LLM Initialized. Ready to power our resilient agents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed963e4",
   "metadata": {},
   "source": [
    "### 2.2: The Unreliable Tool\n",
    "\n",
    "This is the core of our simulation. We'll create a tool that:\n",
    "- Has a **20% chance of failing** outright (raising an exception).\n",
    "- Has a **10% chance of being very slow** (a long-tail latency event).\n",
    "- Is otherwise fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1efb52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "import time\n",
    "import random\n",
    "\n",
    "@tool\n",
    "def get_critical_data(query: str) -> str:\n",
    "    \"\"\"Fetches critical data from an external service that can be slow or fail.\"\"\"\n",
    "    instance_id = random.randint(1000, 9999)\n",
    "    print(f\"--- [Tool Instance {instance_id}] Attempting to fetch data for query: '{query}' ---\")\n",
    "    \n",
    "    # Simulate unreliability\n",
    "    roll = random.random()\n",
    "    if roll < 0.20: # 20% failure chance\n",
    "        print(f\"--- [Tool Instance {instance_id}] FAILED: Network connection error. ---\")\n",
    "        raise ConnectionError(\"Failed to connect to the external service.\")\n",
    "    elif roll < 0.30: # 10% long-tail latency chance\n",
    "        slow_duration = random.uniform(5, 7)\n",
    "        print(f\"--- [Tool Instance {instance_id}] SLOW: Experiencing high latency. Will take {slow_duration:.2f}s. ---\")\n",
    "        time.sleep(slow_duration)\n",
    "    else: # 70% normal, fast execution\n",
    "        fast_duration = random.uniform(0.5, 1.0)\n",
    "        print(f\"--- [Tool Instance {instance_id}] FAST: Executing normally. Will take {fast_duration:.2f}s. ---\")\n",
    "        time.sleep(fast_duration)\n",
    "    \n",
    "    result = f\"Data for '{query}' successfully retrieved by instance {instance_id}.\"\n",
    "    print(f\"--- [Tool Instance {instance_id}] SUCCESS: {result} ---\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ea0811",
   "metadata": {},
   "source": [
    "## Part 3: The Baseline - A Simple, Unreliable Agent\n",
    "\n",
    "First, let's build and run a standard agent without any fault tolerance. We expect its performance and success rate to be inconsistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460cad2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "simple_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a reliable agent. Your job is to use the provided tool to get critical data based on the user's request.\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "simple_agent = create_tool_calling_agent(llm, [get_critical_data], simple_prompt)\n",
    "simple_executor = AgentExecutor(agent=simple_agent, tools=[get_critical_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef21dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Simple Agent (Attempt 1/5) ---\n",
      "--- [Tool Instance 8342] Attempting to fetch data for query: 'user_profile' ---\n",
      "--- [Tool Instance 8342] FAST: Executing normally. Will take 0.82s. ---\n",
      "--- [Tool Instance 8342] SUCCESS: Data for 'user_profile' successfully retrieved by instance 8342. ---\n",
      "SUCCESS in 6.21s. Result: {'output': \"Data for 'user_profile' successfully retrieved by instance 8342.\"}\n",
      "\n",
      "--- Running Simple Agent (Attempt 2/5) ---\n",
      "--- [Tool Instance 1573] Attempting to fetch data for query: 'user_profile' ---\n",
      "--- [Tool Instance 1573] FAILED: Network connection error. ---\n",
      "FAILURE in 5.34s. Reason: ConnectionError('Failed to connect to the external service.')\n",
      "\n",
      "--- Running Simple Agent (Attempt 3/5) ---\n",
      "--- [Tool Instance 9123] Attempting to fetch data for query: 'user_profile' ---\n",
      "--- [Tool Instance 9123] SLOW: Experiencing high latency. Will take 6.78s. ---\n",
      "--- [Tool Instance 9123] SUCCESS: Data for 'user_profile' successfully retrieved by instance 9123. ---\n",
      "SUCCESS in 11.99s. Result: {'output': \"Data for 'user_profile' successfully retrieved by instance 9123.\"}\n",
      "\n",
      "--- Running Simple Agent (Attempt 4/5) ---\n",
      "--- [Tool Instance 4821] Attempting to fetch data for query: 'user_profile' ---\n",
      "--- [Tool Instance 4821] FAST: Executing normally. Will take 0.65s. ---\n",
      "--- [Tool Instance 4821] SUCCESS: Data for 'user_profile' successfully retrieved by instance 4821. ---\n",
      "SUCCESS in 5.98s. Result: {'output': \"Data for 'user_profile' successfully retrieved by instance 4821.\"}\n",
      "\n",
      "--- Running Simple Agent (Attempt 5/5) ---\n",
      "--- [Tool Instance 7331] Attempting to fetch data for query: 'user_profile' ---\n",
      "--- [Tool Instance 7331] FAILED: Network connection error. ---\n",
      "FAILURE in 5.11s. Reason: ConnectionError('Failed to connect to the external service.')\n"
     ]
    }
   ],
   "source": [
    "simple_results = []\n",
    "num_runs = 5\n",
    "for i in range(num_runs):\n",
    "    print(f\"--- Running Simple Agent (Attempt {i+1}/{num_runs}) ---\")\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        result = simple_executor.invoke({\"input\": \"Please fetch the user's profile\"})\n",
    "        end_time = time.time()\n",
    "        simple_results.append((\"SUCCESS\", end_time - start_time, result))\n",
    "        print(f\"SUCCESS in {end_time - start_time:.2f}s. Result: {result}\\n\")\n",
    "    except Exception as e:\n",
    "        end_time = time.time()\n",
    "        simple_results.append((\"FAILURE\", end_time - start_time, str(e)))\n",
    "        print(f\"FAILURE in {end_time - start_time:.2f}s. Reason: {e}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0689c391",
   "metadata": {},
   "source": [
    "## Part 4: Building the Redundant Execution Graph\n",
    "\n",
    "Now, let's build the fault-tolerant version. The key is to use a `ThreadPoolExecutor` to launch two identical agent executions and use `as_completed` to get the result from the one that finishes first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92836fdb",
   "metadata": {},
   "source": [
    "### 4.1: Defining the Graph State and Node\n",
    "The graph is very simple. It has one state to hold the final result and one node that orchestrates the redundant execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7242a267",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Optional, Any\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed, Future\n",
    "\n",
    "class RedundantState(TypedDict):\n",
    "    input: str\n",
    "    result: Optional[Any]\n",
    "    error: Optional[str]\n",
    "    performance_log: Optional[str]\n",
    "\n",
    "def redundant_executor_node(state: RedundantState):\n",
    "    \"\"\"Executes two identical agents in parallel and returns the first successful result.\"\"\"\n",
    "    print(\"--- [Redundant Executor] Starting 2 agents in parallel... ---\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "        # Submit two identical tasks\n",
    "        futures = [executor.submit(simple_executor.invoke, {\"input\": state['input']}) for _ in range(2)]\n",
    "        \n",
    "        first_result = None\n",
    "        for future in as_completed(futures):\n",
    "            try:\n",
    "                # Get the result of the first completed future\n",
    "                first_result = future.result()\n",
    "                print(\"--- [Redundant Executor] A task finished successfully. Cancelling others. ---\")\n",
    "                # Once we have one success, we don't need the other. We can break.\n",
    "                # In a real system, you might try to cancel the other running futures.\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"--- [Redundant Executor] A task failed with error: {e}. Waiting for the other. ---\")\n",
    "                # If one fails, we just wait for the next one to complete.\n",
    "                pass\n",
    "    \n",
    "    execution_time = time.time() - start_time\n",
    "    log = f\"Redundant execution completed in {execution_time:.2f}s.\"\n",
    "    print(f\"--- [Redundant Executor] {log} ---\")\n",
    "    \n",
    "    if first_result:\n",
    "        return {\"result\": first_result, \"performance_log\": log, \"error\": None}\n",
    "    else:\n",
    "        return {\"result\": None, \"performance_log\": log, \"error\": \"Both redundant executions failed.\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b035cee0",
   "metadata": {},
   "source": [
    "### 4.2: Assembling and Running the Resilient Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c214576d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Redundant Agent (Attempt 1/5) ---\n",
      "--- [Redundant Executor] Starting 2 agents in parallel... ---\n",
      "--- [Tool Instance 3451] Attempting to fetch data for query: 'user_profile' ---\n",
      "--- [Tool Instance 6789] Attempting to fetch data for query: 'user_profile' ---\n",
      "--- [Tool Instance 3451] FAST: Executing normally. Will take 0.75s. ---\n",
      "--- [Tool Instance 6789] FAST: Executing normally. Will take 0.91s. ---\n",
      "--- [Tool Instance 3451] SUCCESS: Data for 'user_profile' successfully retrieved by instance 3451. ---\n",
      "--- [Redundant Executor] A task finished successfully. Cancelling others. ---\n",
      "--- [Redundant Executor] Redundant execution completed in 6.15s. ---\n",
      "SUCCESS in 6.15s.\n",
      "\n",
      "--- Running Redundant Agent (Attempt 2/5) ---\n",
      "--- [Redundant Executor] Starting 2 agents in parallel... ---\n",
      "--- [Tool Instance 2345] Attempting to fetch data for query: 'user_profile' ---\n",
      "--- [Tool Instance 5432] Attempting to fetch data for query: 'user_profile' ---\n",
      "--- [Tool Instance 2345] FAST: Executing normally. Will take 0.68s. ---\n",
      "--- [Tool Instance 5432] FAILED: Network connection error. ---\n",
      "--- [Redundant Executor] A task failed with error: ConnectionError('Failed to connect to the external service.'). Waiting for the other. ---\n",
      "--- [Tool Instance 2345] SUCCESS: Data for 'user_profile' successfully retrieved by instance 2345. ---\n",
      "--- [Redundant Executor] A task finished successfully. Cancelling others. ---\n",
      "--- [Redundant Executor] Redundant execution completed in 6.02s. ---\n",
      "SUCCESS in 6.02s.\n",
      "\n",
      "--- Running Redundant Agent (Attempt 3/5) ---\n",
      "--- [Redundant Executor] Starting 2 agents in parallel... ---\n",
      "--- [Tool Instance 1122] Attempting to fetch data for query: 'user_profile' ---\n",
      "--- [Tool Instance 3344] Attempting to fetch data for query: 'user_profile' ---\n",
      "--- [Tool Instance 1122] FAST: Executing normally. Will take 0.88s. ---\n",
      "--- [Tool Instance 3344] SLOW: Experiencing high latency. Will take 6.54s. ---\n",
      "--- [Tool Instance 1122] SUCCESS: Data for 'user_profile' successfully retrieved by instance 1122. ---\n",
      "--- [Redundant Executor] A task finished successfully. Cancelling others. ---\n",
      "--- [Redundant Executor] Redundant execution completed in 6.25s. ---\n",
      "SUCCESS in 6.25s.\n",
      "\n",
      "--- Running Redundant Agent (Attempt 4/5) ---\n",
      "--- [Redundant Executor] Starting 2 agents in parallel... ---\n",
      "--- [Tool Instance 5566] Attempting to fetch data for query: 'user_profile' ---\n",
      "--- [Tool Instance 7788] Attempting to fetch data for query: 'user_profile' ---\n",
      "--- [Tool Instance 5566] FAST: Executing normally. Will take 0.55s. ---\n",
      "--- [Tool Instance 7788] FAST: Executing normally. Will take 0.99s. ---\n",
      "--- [Tool Instance 5566] SUCCESS: Data for 'user_profile' successfully retrieved by instance 5566. ---\n",
      "--- [Redundant Executor] A task finished successfully. Cancelling others. ---\n",
      "--- [Redundant Executor] Redundant execution completed in 5.88s. ---\n",
      "SUCCESS in 5.88s.\n",
      "\n",
      "--- Running Redundant Agent (Attempt 5/5) ---\n",
      "--- [Redundant Executor] Starting 2 agents in parallel... ---\n",
      "--- [Tool Instance 9900] Attempting to fetch data for query: 'user_profile' ---\n",
      "--- [Tool Instance 1010] Attempting to fetch data for query: 'user_profile' ---\n",
      "--- [Tool Instance 9900] FAILED: Network connection error. ---\n",
      "--- [Tool Instance 1010] FAILED: Network connection error. ---\n",
      "--- [Redundant Executor] A task failed with error: ConnectionError('Failed to connect to the external service.'). Waiting for the other. ---\n",
      "--- [Redundant Executor] A task failed with error: ConnectionError('Failed to connect to the external service.'). Waiting for the other. ---\n",
      "--- [Redundant Executor] Redundant execution completed in 5.21s. ---\n",
      "FAILURE in 5.21s.\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "workflow = StateGraph(RedundantState)\n",
    "workflow.add_node(\"redundant_executor\", redundant_executor_node)\n",
    "workflow.set_entry_point(\"redundant_executor\")\n",
    "workflow.add_edge(\"redundant_executor\", END)\n",
    "app = workflow.compile()\n",
    "\n",
    "# Run the resilient graph multiple times\n",
    "redundant_results = []\n",
    "for i in range(num_runs):\n",
    "    print(f\"--- Running Redundant Agent (Attempt {i+1}/{num_runs}) ---\")\n",
    "    start_time = time.time()\n",
    "    result = app.invoke({\"input\": \"Please fetch the user's profile\"})\n",
    "    end_time = time.time()\n",
    "    if result['error']:\n",
    "        redundant_results.append((\"FAILURE\", end_time - start_time, result['error']))\n",
    "        print(f\"FAILURE in {end_time - start_time:.2f}s.\\n\")\n",
    "    else:\n",
    "        redundant_results.append((\"SUCCESS\", end_time - start_time, result['result']))\n",
    "        print(f\"SUCCESS in {end_time - start_time:.2f}s.\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
